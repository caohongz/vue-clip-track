<template>
  <div class="audio-clip" ref="clipRef">
    <!-- åŠ è½½ä¸­çŠ¶æ€ -->
    <div v-if="isLoading" class="audio-clip__loading">
      <span class="audio-clip__loading-spinner"></span>
      <span class="audio-clip__loading-text">åŠ è½½æ³¢å½¢...</span>
    </div>
    <!-- æ³¢å½¢å±•ç¤º -->
    <canvas v-else ref="canvasRef" class="audio-clip__waveform" :width="canvasWidth" :height="canvasHeight" />
    <div class="audio-clip__info">
      <span class="audio-clip__name">{{ clipName }}</span>
      <span v-if="mediaClip.volume !== undefined" class="audio-clip__volume">
        ğŸ”Š {{ Math.round(mediaClip.volume * 100) }}%
      </span>
    </div>
  </div>
</template>

<script setup lang="ts">
import { ref, computed, onMounted, watch, onUnmounted, nextTick } from 'vue'
import { useScaleStore } from '@/stores/scale'
import { extractAudioWaveform, extractVideoAudioWaveform } from '@/utils/mediaProcessor'
import type { MediaClip } from '@/types'

// Props
interface Props {
  clip: MediaClip
}

const props = defineProps<Props>()

// Stores
const scaleStore = useScaleStore()

// Refs
const clipRef = ref<HTMLElement>()
const canvasRef = ref<HTMLCanvasElement>()
const canvasWidth = ref(400)
const canvasHeight = ref(32)
const isLoading = ref(false)
const loadedWaveformData = ref<number[]>([])

// ResizeObserver
let resizeObserver: ResizeObserver | null = null

// Computed
const mediaClip = computed(() => props.clip as MediaClip)

const clipName = computed(() => {
  if (mediaClip.value.name) return mediaClip.value.name
  const url = mediaClip.value.sourceUrl
  const parts = url.split('/')
  return parts[parts.length - 1] || 'Audio'
})

// è·å–å®Œæ•´çš„åŸå§‹æ³¢å½¢æ•°æ®
const fullWaveformData = computed(() => {
  // ä¼˜å…ˆä½¿ç”¨ clip ä¸Šå·²æœ‰çš„æ³¢å½¢æ•°æ®
  if (mediaClip.value.waveformData && mediaClip.value.waveformData.length > 0) {
    return mediaClip.value.waveformData
  }
  // å¦åˆ™ä½¿ç”¨åŠ¨æ€åŠ è½½çš„æ³¢å½¢æ•°æ®
  return loadedWaveformData.value
})

// æ ¹æ® trimStart å’Œ trimEnd è·å–åº”è¯¥å±•ç¤ºçš„æ³¢å½¢æ•°æ®
const waveformData = computed(() => {
  const fullData = fullWaveformData.value
  if (!fullData || fullData.length === 0) return []

  const originalDuration = mediaClip.value.originalDuration
  if (originalDuration <= 0) return fullData

  const trimStart = mediaClip.value.trimStart || 0
  const trimEnd = mediaClip.value.trimEnd || originalDuration

  // è®¡ç®—æ³¢å½¢æ•°æ®çš„èµ·å§‹å’Œç»“æŸç´¢å¼•
  const totalSamples = fullData.length
  const startIndex = Math.floor((trimStart / originalDuration) * totalSamples)
  const endIndex = Math.ceil((trimEnd / originalDuration) * totalSamples)

  // è¿”å›æˆªå–åçš„æ•°æ®
  return fullData.slice(startIndex, endIndex)
})

// ç»˜åˆ¶æ³¢å½¢å›¾
function drawWaveform() {
  if (!canvasRef.value) return

  const canvas = canvasRef.value
  const ctx = canvas.getContext('2d')
  if (!ctx) return

  // æ¸…ç©ºç”»å¸ƒ
  ctx.clearRect(0, 0, canvas.width, canvas.height)

  // å¦‚æœæœ‰æ³¢å½¢æ•°æ®ï¼Œç»˜åˆ¶æ³¢å½¢
  if (waveformData.value && waveformData.value.length > 0) {
    drawRealWaveform(ctx, waveformData.value)
  } else {
    // ç»˜åˆ¶å ä½ç¬¦æ³¢å½¢
    drawPlaceholderWaveform(ctx)
  }
}

// ç»˜åˆ¶çœŸå®æ³¢å½¢
function drawRealWaveform(ctx: CanvasRenderingContext2D, data: number[]) {
  const width = canvasWidth.value
  const height = canvasHeight.value
  // æŸ±å½¢å®½åº¦è®¡ç®—ï¼šä½¿ç”¨æ€»å®½åº¦é™¤ä»¥æ•°æ®é•¿åº¦
  const barSpacing = width / data.length
  // å®é™…æŸ±å½¢å®½åº¦ä¸ºé—´è·çš„ 75%
  const barWidth = Math.max(1, barSpacing * 0.75)

  // åˆ›å»ºæ¸å˜
  const gradient = ctx.createLinearGradient(0, 0, 0, height)
  gradient.addColorStop(0, 'rgba(16, 185, 129, 0.9)')
  gradient.addColorStop(0.5, 'rgba(16, 185, 129, 1)')
  gradient.addColorStop(1, 'rgba(16, 185, 129, 0.9)')

  ctx.fillStyle = gradient

  // ç»˜åˆ¶å¯¹ç§°æ³¢å½¢
  for (let i = 0; i < data.length; i++) {
    // æŸ±å½¢å±…ä¸­æ”¾ç½®åœ¨é—´è·ä¸­
    const x = i * barSpacing + (barSpacing - barWidth) / 2
    const amplitude = data[i] * height * 0.85
    const y = (height - amplitude) / 2

    // ç»˜åˆ¶åœ†è§’çŸ©å½¢
    const radius = Math.min(1, barWidth / 2)

    ctx.beginPath()
    ctx.roundRect(x, y, barWidth, amplitude, radius)
    ctx.fill()
  }

  // ç»˜åˆ¶ä¸­å¿ƒçº¿
  ctx.strokeStyle = 'rgba(255, 255, 255, 0.3)'
  ctx.lineWidth = 1
  ctx.beginPath()
  ctx.moveTo(0, height / 2)
  ctx.lineTo(width, height / 2)
  ctx.stroke()
}

// ç»˜åˆ¶å ä½ç¬¦æ³¢å½¢
function drawPlaceholderWaveform(ctx: CanvasRenderingContext2D) {
  const width = canvasWidth.value
  const height = canvasHeight.value
  const bars = Math.max(20, Math.floor(width / 8))

  ctx.fillStyle = 'rgba(16, 185, 129, 0.5)'

  // ä½¿ç”¨ä¼ªéšæœºç”Ÿæˆä¸€è‡´çš„å ä½ç¬¦æ³¢å½¢
  const seed = mediaClip.value.id.split('').reduce((a, b) => a + b.charCodeAt(0), 0)

  for (let i = 0; i < bars; i++) {
    const x = (i / bars) * width
    // ä½¿ç”¨æ­£å¼¦æ³¢ + å™ªå£°ç”Ÿæˆæ³¢å½¢
    const noise = Math.sin(seed + i * 0.5) * 0.3 + Math.sin(seed + i * 1.3) * 0.2
    const barHeight = (0.3 + Math.abs(noise) * 0.5) * height
    const y = (height - barHeight) / 2

    ctx.fillRect(x, y, width / bars - 1, barHeight)
  }
}

// æ›´æ–° canvas å°ºå¯¸
function updateCanvasSize() {
  if (!clipRef.value) return

  const rect = clipRef.value.getBoundingClientRect()
  canvasWidth.value = Math.max(100, rect.width)
  canvasHeight.value = Math.max(24, rect.height - 20) // å‡å» info åŒºåŸŸé«˜åº¦

  nextTick(() => {
    drawWaveform()
  })
}

// åŠ è½½æ³¢å½¢æ•°æ®
async function loadWaveform() {
  // å¦‚æœå·²ç»æœ‰æ³¢å½¢æ•°æ®ï¼Œä¸éœ€è¦åŠ è½½
  if (mediaClip.value.waveformData && mediaClip.value.waveformData.length > 0) {
    return
  }

  const sourceUrl = mediaClip.value.sourceUrl
  if (!sourceUrl) return

  isLoading.value = true
  try {
    // æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©æå–æ–¹æ³•
    // ä½¿ç”¨æ›´å¤šé‡‡æ ·ç‚¹ï¼ˆ500ï¼‰ä»¥è·å–å®Œæ•´ç²¾ç»†çš„æ³¢å½¢æ•°æ®
    const isVideo = sourceUrl.match(/\.(mp4|webm|mov|avi)$/i)
    const result = isVideo
      ? await extractVideoAudioWaveform(sourceUrl, { samples: 500 })
      : await extractAudioWaveform(sourceUrl, { samples: 500 })

    loadedWaveformData.value = result.waveformData
  } catch (error) {
    console.error('Failed to load audio waveform:', error)
  } finally {
    isLoading.value = false
    nextTick(() => {
      drawWaveform()
    })
  }
}

// ç›‘å¬ sourceUrl å˜åŒ–
watch(() => mediaClip.value.sourceUrl, () => {
  loadedWaveformData.value = []
  loadWaveform()
})

// ç›‘å¬æ³¢å½¢æ•°æ®å˜åŒ–
watch(waveformData, () => {
  nextTick(() => {
    drawWaveform()
  })
})

// ç›‘å¬ trimStart/trimEnd å˜åŒ–ï¼Œé‡æ–°ç»˜åˆ¶æ³¢å½¢
watch(
  () => [mediaClip.value.trimStart, mediaClip.value.trimEnd],
  () => {
    nextTick(() => {
      drawWaveform()
    })
  }
)

// ç›‘å¬ç¼©æ”¾å˜åŒ–
watch(() => scaleStore.actualPixelsPerSecond, () => {
  updateCanvasSize()
})

// ç»„ä»¶æŒ‚è½½æ—¶
onMounted(() => {
  // è®¾ç½® ResizeObserver
  if (clipRef.value) {
    resizeObserver = new ResizeObserver(() => {
      updateCanvasSize()
    })
    resizeObserver.observe(clipRef.value)
  }

  updateCanvasSize()
  loadWaveform()
})

// ç»„ä»¶å¸è½½æ—¶æ¸…ç†
onUnmounted(() => {
  if (resizeObserver) {
    resizeObserver.disconnect()
    resizeObserver = null
  }
})
</script>

<style scoped>
.audio-clip {
  width: 100%;
  height: 100%;
  display: flex;
  flex-direction: column;
  background: linear-gradient(135deg, #10b981 0%, #059669 100%);
  border-radius: inherit;
  overflow: hidden;
  position: relative;
}

.audio-clip__loading {
  position: absolute;
  inset: 0;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  gap: 4px;
  background: rgba(0, 0, 0, 0.3);
}

.audio-clip__loading-spinner {
  width: 18px;
  height: 18px;
  border: 2px solid rgba(255, 255, 255, 0.3);
  border-top-color: white;
  border-radius: 50%;
  animation: spin 0.8s linear infinite;
}

.audio-clip__loading-text {
  font-size: 9px;
  color: rgba(255, 255, 255, 0.8);
}

@keyframes spin {
  to {
    transform: rotate(360deg);
  }
}

.audio-clip__waveform {
  flex: 1;
  width: 100%;
  display: block;
}

.audio-clip__info {
  position: absolute;
  top: 0;
  left: 0;
  display: flex;
  align-items: center;
  justify-content: space-between;
  padding: 2px 6px;
  background: rgba(0, 0, 0, 0.4);
  font-size: 10px;
  font-weight: 500;
  color: #fff;
  white-space: nowrap;
  overflow: hidden;
  flex-shrink: 0;
}

.audio-clip__name {
  flex: 1;
  overflow: hidden;
  text-overflow: ellipsis;
}

.audio-clip__volume {
  padding: 1px 4px;
  background: rgba(255, 255, 255, 0.2);
  border-radius: 2px;
  font-size: 9px;
  font-weight: 600;
  margin-left: 4px;
}
</style>
